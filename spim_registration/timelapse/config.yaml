common: {
  # ============================================================================
  #
  # yaml example file for single channel processing
  #
  # General settings for processing
  #
  # ============================================================================
  # directory that contains the bean shell scripts and Snakefile
  bsh_directory: "/projects/pilot_spim/Christopher/snakemake-workflows/spim_registration/timelapse/",
  # Directory that contains the cuda libraries
  directory_cuda: "/sw/users/schmied/cuda/",
  # Directory that contains the current working Fiji
  fiji-app: "/sw/users/schmied/packages/2015-06-30_Fiji.app.cuda/ImageJ-linux64",
  fiji-prefix: "/sw/users/schmied/packages/xvfb-run -a",       # calls xvfb for Fiji headless mode
  sysconfcpus: "sysconfcpus -n",
  # ============================================================================
  # Processing switches
  # Description: Use switches to decide which processing steps you need:
  #
  # Options:
  #           transformation_switch: "timelapse",
  #           goes directly into fusion after timelapse registration
  #
  #           transformation_switch: "timelapse_duplicate",
  #           for dual channel processing one channel contains the beads
  #           dublicates the transformation from the source channel to the 
  #           target channel
  #
  #           Switches between content based fusion and deconvoltion
  #           fusion_switch: "deconvolution", > for deconvolution
  #           fusion_switch: "fusion", > for content based fusion
  # ============================================================================
  # Transformation switch:
  transformation_switch: "timelapse",
  # Fusion switch:
  fusion_switch: "deconvolution",
  # ============================================================================
  # xml file name
  # 
  # Description: xml file name without .xml suffix
  # ============================================================================
  hdf5_xml_filename: '"single"', 
  # ============================================================================
  # Describe the dataset
  #
  # Options: number of timepoints
  #          angles
  #          channels
  #          illuminations
  #          Settings for .czi or .tif files
  # ============================================================================
  ntimepoints: 2,        # number of timepoints of dataset
  angles: "0,72,144,216,288",   # format e.g.: "0,72,144,216,288",
  channels: "green",     # format e.g.: "green,red", IMPORTANT: for tif numeric!
  illumination: "0",     # format e.g.: "0,1",
  # ----------------------------------------------------------------------------
  # Settings for .czi files
  first_czi: "2015-02-21_LZ1_Stock68_3.czi", 
  # ----------------------------------------------------------------------------
  # Settings for .tif datasets
  # Options: 
  #          file pattern of .tif files:
  #          multi channel with one file per channel: 
  #          spim_TL{tt}_Angle{a}_Channel{c}.tif
  #          for padded zeros use tt 
  image_file_pattern: 'img_TL{{t}}_Angle{{a}}.tif',
  multiple_channels: '"NO (one channel)"',         # '"YES (all channels in one file)"' or '"YES (one file per channel)"' or '"NO (one channel)"'
  # ============================================================================
  # Detection and registration
  #
  # Description: settings for interest point detection and registration
  # Options: Single channel and dual channel processing
  #          Source and traget for dual channel one channel contains the beads
  #          Interestpoints label
  #          Difference-of-mean or difference-of-gaussian detection
  # ============================================================================
  # reg_process_channel:
  # Single Channel: '"All channels"'
  # Dual Channel: '"All channels"'
  # Dual Channel one Channel contains beads: '"Single channel (Select from List)"'
  reg_process_channel: '"All channels"',
  #
  # Dual channel 1 Channel contains the beads: which channel contains the beads?
  # Ignore if Single Channel or Dual Channel both channels contain beads
  source_channel: "red", # channel that contains the beads
  target_channel: "green", # channel without beads
  # reg_interest_points_channel:
  # Single Channel: '"beads"'
  # Dual Channel: '"beads,beads"'
  # Dual Channel: Channel does not contain the beads '"[DO NOT register this channel],beads"'
  reg_interest_points_channel: '"beads"',
  #
  # type of detection: '"Difference-of-Mean (Integral image based)"' or '"Difference-of-Gaussian"'
  type_of_detection: '"Difference-of-Gaussian"',
  # Settings for Difference-of-Mean
  # For multiple channels 'value1,value2' delimiter is ,
  reg_radius_1: '2',
  reg_radius_2: '3',
  reg_threshold: '0.005',
  # Settings for Difference-of-Gaussian
  # For multiple channels 'value1,value2' delimiter is ,
  sigma: '1.3',
  threshold_gaussian: '0.025',
  # ============================================================================
  # Timelapse registration
  #
  # Description: settings for timelapse registration
  # Options: reference timepoint
  # ============================================================================
  reference_timepoint: '1',   # Reference timepoint
  # ============================================================================
  # Content-based multiview fusion
  #
  # Description: settings for content-based multiview fusion
  # Options: downsampling
  #          Cropping parameters based on full resolution
  # ============================================================================
  downsample: '2',    # set downsampling
  minimal_x: '190',   # Cropping parameters of full resolution
  minimal_y: '-16',
  minimal_z: '-348',
  maximal_x: '1019',
  maximal_y: '1941',
  maximal_z: '486',
  # ============================================================================
  # External transformation switch
  #
  # Description: Allows downsampling prior deconvolution
  # Options: no downsampling 
  #          external_trafo_switch: "_transform",
  #
  #          downsampling
  #          external_trafo_switch: "external_trafo",
  #          IMPORTANT: boundingbox needs to reflect this downsampling. 
  #
  #          Matrix for downsampling
  # ============================================================================
  # External transformation switch:
  external_trafo_switch: "_transform",
  #
  # Matrix for downsampling
  matrix_transform: '"0.5, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0"',
  # ============================================================================
  # Multiview deconvolution
  #
  # Description: settings for multiview deconvolution
  # Options: 
  #          number of iterations
  #          Cropping parameters taking downsampling into account!
  #          Channel settings for deconvolution
  # ============================================================================
  iterations: '2',        # number of iterations
  minimal_x_deco: '95',  # Cropping parameters: take downsampling into account
  minimal_y_deco: '-8',
  minimal_z_deco: '-174',
  maximal_x_deco: '509',
  maximal_y_deco: '970',
  maximal_z_deco: '243',
  # Channel settings for deconvolution
  # Single Channel: '"beads"'
  # Dual Channel: '"beads,beads"'
  # Dual Channel one channel contains beads: '"[Same PSF as channel red],beads"'
  detections_to_extract_psf_for_channel: '"beads"',
  #
  # ============================================================================
  # Resave output
  #
  # Description: writes new hdf5 dataset for fusion output
  # Options: Naming pattern of output based on channel number
  #          Channel settings
  #          File name for resaving output into hdf5
  #          Pixel size > isotropic resolution
  #          Image type (16Bit from content-based fusion, 32Bit from deconvolution)
  # ============================================================================
  # Calibration
  manual_calibration_output: "Yes", # calibration override: No or Yes
  # pixel size of output: take downsampling into account!
  output_pixel_distance_x: 0.57, 
  output_pixel_distance_y: 0.57,
  output_pixel_distance_z: 0.57,
  output_pixel_unit: 'um'
  }
  # ============================================================================
  # Advanced settings
  # ============================================================================
  
define_xml_czi: {
  manual_calibration_czi: "No", # calibration override: No or Yes
  czi_pixel_distance_x: '0.285901069641113',  # Manual calibration x
  czi_pixel_distance_y: '0.285901069641113',  # Manual calibration y
  czi_pixel_distance_z: '1.500000000000000',  # Manual calibration z
  czi_pixel_unit: "um",             # unit of manual calibration
  rotation_around: "X-Axis",       # axis of acquistion
  bsh_file: "define_czi.bsh"       # .bsh script for defining .czi file
  }
  
define_xml_tif: {
  # Settings for ImageJ Opener
  manual_calibration_tif: "No", # calibration override: No or Yes
  pixel_distance_x: '0.285901069641113',  # Manual calibration x
  pixel_distance_y: '0.285901069641113',  # Manual calibration y
  pixel_distance_z: '1.500000000000000',  # Manual calibration z
  pixel_unit: "um",             # unit of manual calibration
  type_of_dataset: '"Image Stacks (LOCI Bioformats)"', # '"Image Stacks (ImageJ Opener)"' or '"Image Stacks (LOCI Bioformats)"'
  multiple_timepoints: '"YES (one file per time-point)"', # or NO (one time-point)
  multiple_angles: '"YES (one file per angle)"',          # or NO (one angle)
  multiple_illumination_directions: '"NO (one illumination direction)"', # or YES (one file per illumination direction)
  imglib_container: '"ArrayImg (faster)"',        # '"ArrayImg (faster)"'
  bsh_file: "define_tif_zip.bsh"
  }
  
resave_hdf5: {
  # Resaves .tif or .czi data into hdf5
  # Subsampling and resolution settings for hdf5: data dependent
  hdf5_chunk_sizes: '"{{ {{32,32,4}}, {{32,32,4}}, {{16,16,16}}, {{16,16,16}} }}"',
  subsampling_factors: '"{{ {{1,1,1}}, {{2,2,1}}, {{4,4,1}}, {{8,8,1}} }}"',
  # Standard settings for cluster processing
  setups_per_partition: '0',
  timepoints_per_partition: '1',
  resave_timepoint: '"All Timepoints"',
  resave_angle: '"All angles"',
  resave_channel: '"All channels"',
  resave_illumination: '"All illuminations"',
  num_cores_hdf5_xml: 2,
  num_cores_resave_hdf5: 2,
  bsh_file: "export.bsh"
  }

registration: {
  # Processing setting for Difference-of-Gaussian detection
  # compute_on:'"GPU accurate (Nvidia CUDA via JNA)"'
  compute_on: '"CPU (Java)"',
  separableconvolution: '"libSeparableConvolutionCUDALib.so"',
  # Downsampling settings
  downsample_detection: "Yes", # "No" or "Yes"
  downsample_xy: '"Match Z Resolution (less downsampling)"',
  downsample_z: "1x",
  # Standard Settings for bead based registration
  label_interest_points: '"beads"',              
  reg_process_timepoint: '"Single Timepoint (Select from List)"',
  reg_process_angle: '"All angles"',
  reg_process_illumination: '"All illuminations"',
  subpixel_localization: '"3-dimensional quadratic fit"',
  detection_min_max: "find_maxima",
  type_of_registration: '"Register timepoints individually"',
  algorithm: '"Fast 3d geometric hashing (rotation invariant)"',
  transformation_model: "Affine",
  allowed_error_for_ransac: '5',
  significance: '10',
  fix_tiles: '"Fix first tile"',
  map_back_tiles: '"Map back to first tile using rigid model"',
  model_to_regularize_with: "Rigid",
  lambda: '0.10',
  imglib_container: '"ArrayImg (faster)"',
  num_cores_reg: 2,
  bsh_file: "registration.bsh"  # .bsh script for registration
  }

xml_merge: {
  bsh_file: "xml_merge.bsh"
  }
  
timelapse: {
  # Standard settings for timelapse registration
  type_of_registration_timelapse: '"Match against one reference timepoint (no global optimization)"',
  timelapse_process_timepoints: '"All Timepoints"',
  bsh_file: "timelapse_registration.bsh"
  }
  
dublicate_transformations: {
  # If dual channel processing and only one channel contains beads
  # this allows you to dublicate the transformation for the 
  # channel that does not contain beas
  duplicate_which_transformations: '"Replace all transformations"', # mode of dublication
  bsh_file: "dublicate_transformations.bsh" # .bsh script for dublication
  }
  
fusion: {
  # fused_image: '"Append to current XML Project"', does not work yet
  process_timepoint: '"Single Timepoint (Select from List)"',
  process_angle: '"All angles"',
  process_channel: '"All channels"',
  process_illumination: '"All illuminations"',
  imglib2_container_fusion: '"ArrayImg"',
  interpolation: '"Linear Interpolation"',
  pixel_type: '"16-bit unsigned integer"',
  imglib2_data_container: '"ArrayImg (faster)"',
  process_views_in_paralell: '"All"',
  xml_output: '"Save every XML with user-provided unique id"',
  num_cores_fusion: 6,
  bsh_file: "fusion.bsh"
  }

external_transform: {
  # Downsamples for deconvolution
  # channel setting: '"all_channels"'
  # channel_setting: '"green"',
  transform_timepoint: '"All Timepoints"',
  transform_angle: '"All angles"',
  transform_channel: '"All channels"',
  transform_illumination: '"All illuminations"',
  apply_transformation: '"Current view transformations (appends to current transforms)"',
  define_mode_transform: '"Matrix"',
  transformation: '"Rigid"',
  bsh_file: "transform.bsh"
  }

deconvolution: {
  # Settings for GPU or CPU processing 
  # '"CPU (Java)"' or '"GPU (Nvidia CUDA via JNA)"'
  compute_on: '"GPU (Nvidia CUDA via JNA)"',
  cudafourierconvolution: "libFourierConvolutionCUDALib.so", # GPU processing name of cuda library
  # Standard settings for deconvolution
  process_timepoint: '"Single Timepoint (Select from List)"',
  process_angle: '"All angles"',
  process_channel: '"All channels"',
  process_illumination: '"All illuminations"',
  type_of_iteration: '"Efficient Bayesian - Optimization I (fast, precise)"',
  Tikhonov_parameter: '0.0006',
  compute: '"in 512x512x512 blocks"',
  osem_acceleration: '"1 (balanced)"',
  psf_estimation: '"Extract from beads"',
  psf_size_x: '19',
  psf_size_y: '19',
  psf_size_z: '25',
  imglib2_container: '"ArrayImg"',
  num_cores_deco: 7,
  bsh_file: "deconvolution.bsh"
  }
  
hdf5_output: {
  # if data is 32Bit then the data is converted into 16Bit data
  convert_32bit: '"[Use min/max of first image (might saturate intenities over time)]"',
  # subsampling and chunk size settings: dataset dependent
  subsampling_output: '"{{ {{1,1,1}}, {{2,2,2}}, {{4,4,4}}, {{8,8,8}} }}"', # data dependent
  chunk_sizes_output: '"{{ {{16,16,16}}, {{16,16,16}}, {{16,16,16}}, {{16,16,16}} }}"', # data dependent
  # subsampling_output: '"{{ {{1,1,1}}, {{2,2,2}} }}"',
  # chunk_sizes_output: '"{{ {{16,16,16}}, {{16,16,16}} }}"',
  # Standard settings for hdf5_output
  output_type_of_dataset: '"Image Stacks (ImageJ Opener)"', # '"Image Stacks (ImageJ Opener)"' or '"Image Stacks (LOCI Bioformats)"'
  output_multiple_timepoints: '"YES (one file per time-point)"',
  output_multiple_angles: '"NO (one angle)"',
  output_illumination_directions: '"NO (one illumination direction)"',
  output_imglib_container: '"ArrayImg (faster)"',
  num_cores_hdf5_xml_output: 2,
  num_cores_resave_hdf5_output: 2,
  bsh_file_define: "define_output.bsh", # .bsh script for defining the dataset
  bsh_file_hdf5: "export_output.bsh"    # .bsh script for resaving into hdf5
  }

